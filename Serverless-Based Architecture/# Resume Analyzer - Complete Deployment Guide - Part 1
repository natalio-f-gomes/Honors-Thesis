# Resume Analyzer - Complete Deployment Guide - Part 1
###Partially edited by copilot

This guide documents the complete AWS infrastructure setup for the Resume Analyzer application, including S3, CloudFront, Cognito, Lambda, API Gateway, and DynamoDB.

---

## Table of Contents
1. [Prerequisites](#prerequisites)
2. [S3 Bucket Setup](#s3-bucket-setup)
3. [CloudFront Distribution](#cloudfront-distribution)
4. [Cognito User Pool Setup](#cognito-user-pool-setup)
5. [DynamoDB Table](#dynamodb-table)
6. [Lambda Function Setup](#lambda-function-setup)
7. [API Gateway Configuration](#api-gateway-configuration)
8. [Deployment Script](#deployment-script)
9. [Testing](#testing)

---

## Prerequisites

### Required Tools
- AWS CLI configured with credentials
- Docker Desktop (for building Lambda layers on Windows)
- PowerShell (Windows) or Bash (Linux/Mac)

### Verify AWS CLI
```bash
aws --version
aws sts get-caller-identity
```

### AWS Account Information Needed
- AWS Account ID
- AWS Region (we use `us-east-1`)

---

## S3 Bucket Setup

### 1. Create Private S3 Bucket for Static Website

```bash
aws s3 mb s3://resume-analyzer.net --region us-east-1
```

### 2. Upload Website Files

```bash
aws s3 sync . s3://resume-analyzer.net/ --exclude ".git/*" --exclude "*.json"
```

**Note:** The bucket remains **private** - CloudFront will access it via Origin Access Control (OAC).

---

## CloudFront Distribution

### 1. Create Origin Access Control (OAC)

Create `oac-config.json`:
```json
{
  "Name": "resume-analyzer-oac",
  "Description": "OAC for resume-analyzer.net S3 bucket",
  "SigningProtocol": "sigv4",
  "SigningBehavior": "always",
  "OriginAccessControlOriginType": "s3"
}
```

```bash
aws cloudfront create-origin-access-control --origin-access-control-config file://oac-config.json
```

**Save the returned `Id` - you'll need it next.**

### 2. Create CloudFront Distribution

Create `cloudfront-config.json`:
```json
{
  "CallerReference": "resume-analyzer-2024-11-02",
  "Comment": "CloudFront distribution for resume-analyzer.net",
  "Enabled": true,
  "Origins": {
    "Quantity": 1,
    "Items": [
      {
        "Id": "S3-resume-analyzer",
        "DomainName": "resume-analyzer.net.s3.amazonaws.com",
        "OriginAccessControlId":  OAC_ID_HERE",
        "S3OriginConfig": {
          "OriginAccessIdentity": ""
        }
      }
    ]
  },
  "DefaultRootObject": "index.html",
  "DefaultCacheBehavior": {
    "TargetOriginId": "S3-resume-analyzer",
    "ViewerProtocolPolicy": "redirect-to-https",
    "AllowedMethods": {
      "Quantity": 2,
      "Items": ["GET", "HEAD"],
      "CachedMethods": {
        "Quantity": 2,
        "Items": ["GET", "HEAD"]
      }
    },
    "Compress": true,
    "ForwardedValues": {
      "QueryString": false,
      "Cookies": {
        "Forward": "none"
      }
    },
    "MinTTL": 0,
    "DefaultTTL": 86400,
    "MaxTTL": 31536000,
    "TrustedSigners": {
      "Enabled": false,
      "Quantity": 0
    }
  },
  "ViewerCertificate": {
    "CloudFrontDefaultCertificate": true
  }
}
```


```bash
aws cloudfront create-distribution --distribution-config file://cloudfront-config.json
```

**Save the `Id` and `ARN` from the output.**

### 3. Update S3 Bucket Policy

Create `bucket-policy.json`:
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "AllowCloudFrontServicePrincipal",
      "Effect": "Allow",
      "Principal": {
        "Service": "cloudfront.amazonaws.com"
      },
      "Action": "s3:GetObject",
      "Resource": "arn:aws:s3:::resume-analyzer.net/*",
      "Condition": {
        "StringEquals": {
          "AWS:SourceArn":  DISTRIBUTION_ARN_HERE"
        }
      }
    }
  ]
}
```

Replace  DISTRIBUTION_ARN_HERE` with CloudFront distribution ARN.

```bash
aws s3api put-bucket-policy --bucket resume-analyzer.net --policy file://bucket-policy.json
```

### 4. Get CloudFront Domain

```bash
aws cloudfront list-distributions --query "DistributionList.Items[0].DomainName" --output text
```

**Example output:** `abcdef213rf.cloudfront.net`

---

## Cognito User Pool Setup

### 1. Create User Pool

```bash
aws cognito-idp create-user-pool \
  --pool-name resume-analyzer-users \
  --policies "PasswordPolicy={MinimumLength=8,RequireUppercase=true,RequireLowercase=true,RequireNumbers=true,RequireSymbols=true}" \
  --auto-verified-attributes email \
  --username-attributes email
```

**Save the `UserPool.Id` from output (e.g., `us-east-1__abcd1234_`).**

### 2. Create the App Client

```bash
aws cognito-idp create-user-pool-client \
  --user-pool-id USER_POOL_ID \
  --client-name resume-analyzer-app \
  --generate-secret \
  --allowed-o-auth-flows code \
  --allowed-o-auth-scopes openid email phone profile \
  --callback-urls https://CLOUDFRONT_DOMAIN/html/callback.html \
  --logout-urls https://CLOUDFRONT_DOMAIN/index.html \
  --supported-identity-providers COGNITO \
  --allowed-o-auth-flows-user-pool-client
```

**Save the `ClientId` and `ClientSecret` from the output.**

### 3. Create the Hosted UI Domain

```bash
aws cognito-idp create-user-pool-domain \
  --domain resume-analyzer-bsu \
  --user-pool-id USER_POOL_ID
```

### 4. Update Frontend Configuration

Update `js/auth-cognito-hosted.js`:
```javascript
const CONFIG = {
    region: 'us-east-1',
    userPoolId:  USER_POOL_ID',
    clientId:  CLIENT_ID',
    clientSecret:  CLIENT_SECRET',
    domain: 'resume-analyzer-bsu.auth.us-east-1.amazoncognito.com',
    redirectSignIn: 'https://CLOUDFRONT_DOMAIN/html/callback.html',
    redirectSignOut: 'https://CLOUDFRONT_DOMAIN/index.html',
    scope: ['openid', 'email', 'phone', 'profile']
};
```

---

## DynamoDB Table

### Create Table

```bash
aws dynamodb create-table \
  --table-name resume-analyzer-users-resume \
  --attribute-definitions \
    AttributeName=user_id,AttributeType=S \
    AttributeName=resume_id,AttributeType=S \
  --key-schema \
    AttributeName=user_id,KeyType=HASH \
    AttributeName=resume_id,KeyType=RANGE \
  --billing-mode PAY_PER_REQUEST
```

**Table Structure:**
- Partition Key: `user_id` (String)
- Sort Key: `resume_id` (String)
- Billing: On-Demand

---

## Lambda Function Setup

### 1. Create IAM Role for Lambda

Create `trust-policy.json`:
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "Service": "lambda.amazonaws.com"
      },
      "Action": "sts:AssumeRole"
    }
  ]
}
```

```bash
aws iam create-role \
  --role-name lambda-resume-analyzer-role \
  --assume-role-policy-document file://trust-policy.json
```

### 2. Attach Permissions Policy

Create `lambda-policy.json`:
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "logs:CreateLogGroup",
        "logs:CreateLogStream",
        "logs:PutLogEvents"
      ],
      "Resource": "arn:aws:logs:*:*:*"
    },
    {
      "Effect": "Allow",
      "Action": [
        "s3:PutObject",
        "s3:GetObject"
      ],
      "Resource": "arn:aws:s3:::resume-analyzer-user-data/*"
    },
    {
      "Effect": "Allow",
      "Action": [
        "dynamodb:PutItem",
        "dynamodb:GetItem",
        "dynamodb:Query",
        "dynamodb:UpdateItem"
      ],
      "Resource": "arn:aws:dynamodb:*:*:table/resume-analyzer-users-resume"
    },
    {
      "Effect": "Allow",
      "Action": [
        "ssm:GetParameter"
      ],
      "Resource": "arn:aws:ssm:*:*:parameter/atp-project/django/*"
    },
    {
      "Effect": "Allow",
      "Action": [
        "lambda:InvokeFunction"
      ],
      "Resource": "*"
    }
  ]
}
```

```bash
aws iam put-role-policy \
  --role-name lambda-resume-analyzer-role \
  --policy-name lambda-resume-analyzer-policy \
  --policy-document file://lambda-policy.json
```

### 3. Create S3 Bucket for User Data

```bash
aws s3 mb s3://resume-analyzer-user-data --region us-east-1
```

### 4. Store API Keys in Parameter Store

```bash
# Claude AI API Key
aws ssm put-parameter \
  --name "/atp-project/django/CLAUDE_AI_API_KEY" \
  --value  CLAUDE_API_KEY" \
  --type SecureString

# RapidAPI Key (for job search)
aws ssm put-parameter \
  --name "/atp-project/django/X_RAPID_API_KEY" \
  --value  RAPIDAPI_KEY" \
  --type SecureString
```

### 5. Build Lambda Layer with Dependencies

Create `requirements.txt`:
```txt
boto3
PyPDF2
anthropic
```

Create `Dockerfile`:
```dockerfile
FROM public.ecr.aws/lambda/python:3.11

# Install dependencies
COPY requirements.txt .
RUN pip install -r requirements.txt -t /python

# Create layer structure
RUN mkdir -p /layer/python
RUN cp -r /python/* /layer/python/

CMD ["echo", "Layer built successfully"]
```

Create `build-layer.ps1`:
```powershell
# Build Lambda Layer with Docker

Write-Host "Building Lambda Layer..." -ForegroundColor Green

# Build Docker image
docker build -t lambda-layer-builder .

# Create container and copy layer
docker create --name temp-layer lambda-layer-builder
docker cp temp-layer:/layer ./layer
docker rm temp-layer

# Create ZIP
Write-Host "Creating layer ZIP..." -ForegroundColor Green
Compress-Archive -Path ./layer/python -DestinationPath lambda-layer.zip -Force

# Cleanup
Remove-Item -Recurse -Force ./layer

Write-Host "Layer built: lambda-layer.zip" -ForegroundColor Green
```

**Build the layer:**
```powershell
.\build-layer.ps1
```

**Upload to AWS:**
```bash
aws lambda publish-layer-version \
  --layer-name resume-analyzer-dependencies \
  --zip-file fileb://lambda-layer.zip \
  --compatible-runtimes python3.11
```

**Save the `LayerVersionArn` from output.**

### 6. Create Lambda Function

**Zip the function code:**
```powershell
Compress-Archive -Path lambda1_upload_handler.py -DestinationPath lambda1-function.zip -Force
```

**Create function:**
```bash
aws lambda create-function \
  --function-name upload-handler \
  --runtime python3.11 \
  --role arn:aws:iam: ACCOUNT_ID:role/lambda-resume-analyzer-role \
  --handler lambda1_upload_handler.lambda_handler \
  --zip-file fileb://lambda1-function.zip \
  --timeout 60 \
  --memory-size 512 \
  --layers LAYER_ARN
```

---

## API Gateway Configuration

### 1. Create REST API

```bash
aws apigateway create-rest-api \
  --name resume-analyzer-api \
  --description "Resume Analyzer API" \
  --endpoint-configuration types=REGIONAL
```

**Save the `id` from output.**

### 2. Get Root Resource ID

```bash
aws apigateway get-resources \
  --rest-api-id API_ID \
  --query "items[0].id" \
  --output text
```

### 3. Create `/upload` Resource

```bash
aws apigateway create-resource \
  --rest-api-id API_ID \
  --parent-id ROOT_RESOURCE_ID \
  --path-part upload
```

**Save the resource `id`.**

### 4. Create Cognito Authorizer

```bash
aws apigateway create-authorizer \
  --rest-api-id API_ID \
  --name cognito-authorizer \
  --type COGNITO_USER_POOLS \
  --provider-arns arn:aws:cognito-idp:us-east-1 ACCOUNT_ID:userpool USER_POOL_ID \
  --identity-source method.request.header.Authorization
```

**Save the authorizer `id`.**

### 5. Create POST Method

```bash
aws apigateway put-method \
  --rest-api-id API_ID \
  --resource-id UPLOAD_RESOURCE_ID \
  --http-method POST \
  --authorization-type COGNITO_USER_POOLS \
  --authorizer-id AUTHORIZER_ID
```

### 6. Integrate with Lambda

```bash
aws apigateway put-integration \
  --rest-api-id API_ID \
  --resource-id UPLOAD_RESOURCE_ID \
  --http-method POST \
  --type AWS_PROXY \
  --integration-http-method POST \
  --uri arn:aws:apigateway:us-east-1:lambda:path/2015-03-31/functions/arn:aws:lambda:us-east-1 ACCOUNT_ID:function:upload-handler/invocations
```

### 7. Grant API Gateway Permission to Invoke Lambda

```bash
aws lambda add-permission \
  --function-name upload-handler \
  --statement-id apigateway-invoke \
  --action lambda:InvokeFunction \
  --principal apigateway.amazonaws.com \
  --source-arn arn:aws:execute-api:us-east-1 ACCOUNT_ID API_ID/*/*
```

### 8. Setup CORS (OPTIONS Method)

**Create OPTIONS method:**
```bash
aws apigateway put-method \
  --rest-api-id API_ID \
  --resource-id UPLOAD_RESOURCE_ID \
  --http-method OPTIONS \
  --authorization-type NONE
```

**Create mock integration:**

Create `mock-integration.json`:
```json
{
  "application/json": "{\"statusCode\": 200}"
}
```

```bash
aws apigateway put-integration \
  --rest-api-id API_ID \
  --resource-id UPLOAD_RESOURCE_ID \
  --http-method OPTIONS \
  --type MOCK \
  --request-templates file://mock-integration.json
```

**Set method response:**
```bash
aws apigateway put-method-response \
  --rest-api-id API_ID \
  --resource-id UPLOAD_RESOURCE_ID \
  --http-method OPTIONS \
  --status-code 200 \
  --response-parameters "method.response.header.Access-Control-Allow-Headers=false,method.response.header.Access-Control-Allow-Methods=false,method.response.header.Access-Control-Allow-Origin=false"
```

**Set integration response:**

Create `cors-response.json`:
```json
{
  "method.response.header.Access-Control-Allow-Headers": "'Content-Type,Authorization'",
  "method.response.header.Access-Control-Allow-Methods": "'POST,OPTIONS'",
  "method.response.header.Access-Control-Allow-Origin": "'*'"
}
```

```bash
aws apigateway put-integration-response \
  --rest-api-id API_ID \
  --resource-id UPLOAD_RESOURCE_ID \
  --http-method OPTIONS \
  --status-code 200 \
  --response-parameters file://cors-response.json
```

### 9. Deploy API

```bash
aws apigateway create-deployment \
  --rest-api-id API_ID \
  --stage-name prod
```

* API endpoint:**
```
https:/ API_ID.execute-api.us-east-1.amazonaws.com/prod/upload
```

### 10. Update Frontend with API Endpoint

Update `js/upload.js`:
```javascript
const API_ENDPOINT = 'https:/ API_ID.execute-api.us-east-1.amazonaws.com/prod/upload';
```

---

## Deployment Script

Create `deploy.ps1` for easy redeployment:

```powershell
# Sync files to S3
Write-Host "Syncing files to S3..." -ForegroundColor Green
aws s3 sync . s3://resume-analyzer.net/ --exclude ".git/*" --exclude "*.json" --exclude "*.ps1"

# Get CloudFront Distribution ID
Write-Host "Getting CloudFront Distribution ID..." -ForegroundColor Green
$DistributionId = aws cloudfront list-distributions --query "DistributionList.Items[?Origins.Items[?DomainName=='resume-analyzer.net.s3.amazonaws.com']].Id" --output text

# Create CloudFront invalidation
Write-Host "Creating CloudFront invalidation..." -ForegroundColor Green
aws cloudfront create-invalidation --distribution-id $DistributionId --paths "/*"

Write-Host "Deployment complete!" -ForegroundColor Green
```

**Deploy:**
```powershell
.\deploy.ps1
```

---

## Testing

### 1. View Lambda Logs

```bash
aws logs tail /aws/lambda/upload-handler --follow
```

### 2. Test Upload Flow

1. Navigate to CloudFront URL
2. Click "Login"
3. Sign up/Sign in via Cognito
4. Go to Upload page
5. Upload a PDF resume
6. Monitor Lambda logs for processing

### 3. Verify S3 Storage

```bash
aws s3 ls s3://resume-analyzer-user-data/ --recursive
```

Expected structure:
```
USER_ID/resume-1/resume.pdf
USER_ID/resume-1/resume.json
```

### 4. Verify DynamoDB Entry

```bash
aws dynamodb scan --table-name resume-analyzer-users-resume
```

---

## Architecture Summary

```
┌─────────────┐
│   User      │
└──────┬──────┘
       │ HTTPS
       ▼
┌─────────────────┐         ┌──────────────┐
│  CloudFront     │────────▶│  S3 Bucket   │
│  Distribution   │   OAC   │  (Private)   │
└──────┬──────────┘         └──────────────┘
       │
       │ Authenticated Request
       ▼
┌─────────────────┐         ┌──────────────┐
│  API Gateway    │────────▶│   Cognito    │
│  /prod/upload   │  Auth   │  User Pool   │
└──────┬──────────┘         └──────────────┘
       │
       │ Invoke
       ▼
┌─────────────────┐
│  Lambda         │
│  upload-handler │
└──────┬──────────┘
       │
       ├─────────▶ DynamoDB (metadata)
       │
       ├─────────▶ S3 (resume files)
       │
       └─────────▶ Claude AI (parsing)
```

---

## Key Files Reference

### Frontend Files
- `index.html` - Landing page
- `html/upload.html` - Resume upload page
- `html/callback.html` - Cognito callback handler
- `html/account.html` - User account/resume list
- `html/parsed-resume.html` - Resume details
- `js/auth-cognito-hosted.js` - Authentication logic
- `js/upload.js` - Upload functionality
- `js/main.js` - Main app logic

### Backend Files
- `lambda1_upload_handler.py` - Main Lambda function
- `requirements.txt` - Python dependencies
- `Dockerfile` - Lambda layer builder

### Configuration Files
- `cloudfront-config.json` - CloudFront distribution config
- `oac-config.json` - Origin Access Control config
- `bucket-policy.json` - S3 bucket policy
- `trust-policy.json` - IAM role trust policy
- `lambda-policy.json` - Lambda permissions policy
- `cors-response.json` - API Gateway CORS config
- `mock-integration.json` - OPTIONS mock response

---

## Troubleshooting

### Issue: CloudFront 403 Error
**Solution:** Verify bucket policy includes correct CloudFront distribution ARN

### Issue: Lambda Timeout
**Solution:** Increase timeout (current: 60s)
```bash
aws lambda update-function-configuration \
  --function-name upload-handler \
  --timeout 120
```

### Issue: CORS Errors
**Solution:** Verify OPTIONS method is configured correctly in API Gateway

### Issue: Authentication Failed
**Solution:** 
1. Check Cognito callback URLs match CloudFront domain
2. Verify client secret in frontend config
3. Check authorizer is attached to API method

### Issue: PDF Parsing Failed
**Solution:** Check Claude API key in Parameter Store is valid

---

## Cost Estimation

**Monthly costs (approximate):**
- S3 Storage: $0.023/GB (~$0.50 for 20GB)
- CloudFront: $0.085/GB data transfer (~$8.50 for 100GB)
- Lambda: $0.20 per 1M requests + compute time (~$5-10)
- DynamoDB: Free tier (25GB storage, 25 WCU/RCU)
- API Gateway: $3.50 per million requests
- Cognito: Free tier (50,000 MAU)

**Total estimated: $15-25/month for moderate usage**

---

## Security Best Practices

1.  S3 bucket is private
2.  CloudFront uses OAC for secure S3 access
3.  API requires Cognito authentication
4.  API keys stored in Parameter Store (encrypted)
5.  Lambda has least-privilege IAM role
6.  HTTPS enforced via CloudFront

---

## Next Steps

1. Set up additional Lambda functions for:
   - `get-user-resumes` - List user's resumes
   - `get-resume-json` - Retrieve parsed resume
   - `get-resume-metadata` - Get resume details
   - `get-jobs` - Fetch job listings
   - `recommendations` - Generate recommendations

2. Configure custom domain with Route 53
3. Add SSL certificate with ACM
4. Set up CloudWatch alarms
5. Implement CI/CD pipeline

---

## Support

For issues or questions, refer to:
- AWS Documentation: https://docs.aws.amazon.com/
- Claude API Docs: https://docs.anthropic.com/
- Repository Issues:  GitHub repo]

---

**Last Updated:** November 2, 2025
**Version:** 1.0.0